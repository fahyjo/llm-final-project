{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "🦥 Unsloth Zoo will now patch everything to make training faster!\n",
      "INFO 04-06 00:23:27 [__init__.py:239] Automatically detected platform cuda.\n",
      "Standard import failed for UnslothOnlineDPOTrainer: No module named 'UnslothOnlineDPOTrainer'. Using tempfile instead!\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from typing import List, Dict, Any\n",
    "import json\n",
    "import re\n",
    "\n",
    "import sys\n",
    "import os\n",
    "current_dir = os.path.abspath('')\n",
    "project_root = os.path.dirname(current_dir)\n",
    "sys.path.insert(0, project_root)\n",
    "\n",
    "from grpo.grpo import SYSTEM_PROMPT, extract_trace, optimal_solution_reward_func, improvement_reward_func, valid_response_reward_func, strict_format_reward_func, soft_format_reward_func\n",
    "from tsp.tsp_llm import load_tsp_problem_dataset, coordinates_to_tsp\n",
    "from tsp.tsp import calculate_tsp_distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MODEL = \"unsloth/Qwen2.5-7B-Instruct-bnb-4bit\"\n",
    "BENCHMARK_DATASET = \"tsp_benchmark_dataset.json\"\n",
    "BENCHMARK_RESULTS = \"tsp_benchmark_results_qwen2.5-7B-2.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.3.19: Fast Qwen2 patching. Transformers: 4.50.3. vLLM: 0.8.2.\n",
      "   \\\\   /|    NVIDIA A100-SXM4-40GB. Num GPUs = 1. Max memory: 39.381 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 8.0. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.29.post2. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Qwen2ForCausalLM(\n",
       "  (model): Qwen2Model(\n",
       "    (embed_tokens): Embedding(152064, 3584, padding_idx=151654)\n",
       "    (layers): ModuleList(\n",
       "      (0-27): 28 x Qwen2DecoderLayer(\n",
       "        (self_attn): Qwen2Attention(\n",
       "          (q_proj): Linear4bit(in_features=3584, out_features=3584, bias=True)\n",
       "          (k_proj): Linear4bit(in_features=3584, out_features=512, bias=True)\n",
       "          (v_proj): Linear4bit(in_features=3584, out_features=512, bias=True)\n",
       "          (o_proj): Linear4bit(in_features=3584, out_features=3584, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): Qwen2MLP(\n",
       "          (gate_proj): Linear4bit(in_features=3584, out_features=18944, bias=False)\n",
       "          (up_proj): Linear4bit(in_features=3584, out_features=18944, bias=False)\n",
       "          (down_proj): Linear4bit(in_features=18944, out_features=3584, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
       "      )\n",
       "    )\n",
       "    (norm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
       "    (rotary_emb): LlamaRotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=3584, out_features=152064, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load model and tokenizer\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "  model_name=MODEL,\n",
    "  max_seq_length=4096,\n",
    "  load_in_4bit=True,\n",
    "  dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "# Prepare model for inference\n",
    "FastLanguageModel.for_inference(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_assistant_response_regex(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Extract the assistant's response from the decoded text output of Qwen.\n",
    "    \n",
    "    Args:\n",
    "        text: The decoded text output from the model\n",
    "        \n",
    "    Returns:\n",
    "        str: The extracted assistant response or empty string if no match found\n",
    "    \"\"\"\n",
    "    # Common patterns for assistant responses in chat models\n",
    "    patterns = [\n",
    "        r\"(?:^|\\n)(?:assistant|assistant:)(.*?)(?:$|\\n\\s*(?:user|user:|system|system:|<\\|im_end\\|>))\",  # Matches cases with various endings\n",
    "        r\"<\\|im_start\\|>assistant\\s*(.*?)(?:<\\|im_end\\|>|$)\",  # Matches with special tokens\n",
    "        r\"(?:^|\\n)assistant:\\s*(.*?)(?:$|\\n\\s*(?:user|user:|system|system:))\",  # Standard chat format\n",
    "    ]\n",
    "    \n",
    "    # Try each pattern until we find a match\n",
    "    for pattern in patterns:\n",
    "        matches = re.search(pattern, text, re.DOTALL | re.IGNORECASE)\n",
    "        if matches:\n",
    "            return matches.group(1).strip()\n",
    "    \n",
    "    # If no structured format is found, return everything after the last \"user:\" or system prompt\n",
    "    last_user = re.search(r\"(?:^|\\n)user:(?!.*\\nuser:).*?\\n(.*?)$\", text, re.DOTALL | re.IGNORECASE)\n",
    "    if last_user:\n",
    "        return last_user.group(1).strip()\n",
    "    \n",
    "    # If all else fails, return the original text (this is a fallback)\n",
    "    return text.strip()\n",
    "\n",
    "def generate(prompt: str, max_new_tokens: int = 2500, num_samples: int = 3, temperature: float = 0.7, top_p: float = 0.9) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Generate a response from the model based on the prompt.\n",
    "\n",
    "    Args:\n",
    "        prompt: The input prompt\n",
    "        max_new_tokens: Max number of tokens to generate\n",
    "        num_samples: Number of samples per prompt\n",
    "        temperature: Model temperature\n",
    "        top_p: Model top_p\n",
    "    \n",
    "    Returns:\n",
    "        Dict[str, Any]: Summary dict containing input token count, average output token count, and\n",
    "                        model responses\n",
    "    \"\"\"\n",
    "\n",
    "    # Format chat message for Qwen\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "\n",
    "    # Tokenize input and move input tensors to GPU\n",
    "    inputs = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=True,\n",
    "        add_generation_prompt=True,\n",
    "        return_tensors=\"pt\"\n",
    "    ).to(\"cuda\")\n",
    "\n",
    "    # Get input token count\n",
    "    input_token_count = inputs.shape[1]\n",
    "\n",
    "    # Generate outputs\n",
    "    outputs = model.generate(\n",
    "        input_ids=inputs,\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        num_return_sequences=num_samples,\n",
    "        do_sample=True,\n",
    "        temperature=temperature,\n",
    "        top_p=top_p,\n",
    "        return_dict_in_generate=True,\n",
    "        output_scores=True\n",
    "    )\n",
    "        \n",
    "    # Get output token counts\n",
    "    output_sequences = outputs.sequences\n",
    "    avg_output_token_count = sum([len(o) - input_token_count for o in output_sequences]) / len(output_sequences)\n",
    "        \n",
    "    # Process outputs\n",
    "    responses = [tokenizer.decode(o, skip_special_tokens=True) for o in output_sequences]\n",
    "    responses = [extract_assistant_response_regex(r) for r in responses]\n",
    "\n",
    "    # Return token counts and responses\n",
    "    out = {\n",
    "        \"input token count\": input_token_count,\n",
    "        \"average output token count\": avg_output_token_count,\n",
    "        \"responses\": responses\n",
    "    }\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply Reward Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def apply_reward_functions(problem: Dict, responses: List[str]) -> Dict:\n",
    "    n = len(responses)\n",
    "    tsp = coordinates_to_tsp(problem['coordinates'])\n",
    "\n",
    "    # Extract traces and distances from model responses\n",
    "    traces = [extract_trace(response) for response in responses]\n",
    "    distances = [round(calculate_tsp_distance(tsp, trace)) for trace in traces]\n",
    "    \n",
    "    # Construct args for reward functions\n",
    "    completions = [[{'content': response}] for response in responses]\n",
    "    kwargs = {\n",
    "        'tsp': [tsp for _ in responses],\n",
    "        'answer': [problem['solution'] for _ in responses],\n",
    "        'reference_distance': [problem['reference_distance'] for _ in responses]\n",
    "    }\n",
    "\n",
    "    # Invoke reward functions\n",
    "    optimal_solution_rewards = optimal_solution_reward_func(completions, **kwargs)\n",
    "    improvement_rewards = improvement_reward_func(completions, **kwargs)\n",
    "    valid_response_rewards = valid_response_reward_func(completions, **kwargs)\n",
    "    strict_format_rewards = strict_format_reward_func(completions, **kwargs)\n",
    "    soft_format_rewards = soft_format_reward_func(completions, **kwargs)\n",
    "    \n",
    "    print(\"NEW PROBLEM\")\n",
    "    print(f\"target_distance: {problem['solution']['distance'] * 1.1}\")\n",
    "    for i in range(len(responses)):\n",
    "        print(f\"sample_{i}\")\n",
    "        print(f\"model distance: {distances[i]}, optimal solution reward: {optimal_solution_rewards[i]}, improvement reward: {improvement_rewards[i]}, valid response reward: {valid_response_rewards[i]}, strict format: {strict_format_rewards[i]}, soft format: {soft_format_rewards[i]}\")\n",
    "\n",
    "    # Calculate problem averages\n",
    "    problem_summary = {\n",
    "        \"problem_id\": problem[\"problem_id\"],\n",
    "        \"solution\": problem[\"solution\"],\n",
    "        \"average optimal solution reward\": sum(optimal_solution_rewards) / n,\n",
    "        \"average improvement reward\": sum(improvement_rewards) / n,\n",
    "        \"average valid response reward\": sum(valid_response_rewards) / n,\n",
    "        \"average strict format reward\": sum(strict_format_rewards) / n,\n",
    "        \"average soft format reward\": sum(soft_format_rewards) / n\n",
    "    }\n",
    "\n",
    "    # Add summary for each sample\n",
    "    for i in range(n):\n",
    "        sample_key = f\"sample_{i}\"\n",
    "        problem_summary[sample_key] = {\n",
    "            \"response\": responses[i],\n",
    "            \"solution\": {\n",
    "                \"path\": traces[i],\n",
    "                \"distance\": distances[i]\n",
    "            },\n",
    "            \"optimal solution reward\": optimal_solution_rewards[i],\n",
    "            \"improvement reward\": improvement_rewards[i],\n",
    "            \"valid response reward\": valid_response_rewards[i],\n",
    "            \"strict format reward\": strict_format_rewards[i],\n",
    "            \"soft format reward\": soft_format_rewards[i],\n",
    "        }\n",
    "    \n",
    "    return problem_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Benchmark Dataset and Solve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Solving TSP Benchmark:   0%|          | 0/50 [00:00<?, ?it/s]The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Solving TSP Benchmark:   2%|▏         | 1/50 [01:57<1:36:11, 117.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEW PROBLEM\n",
      "target_distance: 602.8000000000001\n",
      "sample_0\n",
      "model distance: 561, optimal solution reward: 2.5, improvement reward: 0.0, valid response reward: 0.5, strict format: 0.0, soft format: 0.0\n",
      "sample_1\n",
      "model distance: 561, optimal solution reward: 2.5, improvement reward: 0.0, valid response reward: 0.5, strict format: 0.0, soft format: 0.0\n",
      "sample_2\n",
      "model distance: 559, optimal solution reward: 2.5, improvement reward: 2.5, valid response reward: 0.5, strict format: 0.0, soft format: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Solving TSP Benchmark:   4%|▍         | 2/50 [04:03<1:37:53, 122.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEW PROBLEM\n",
      "target_distance: 498.30000000000007\n",
      "sample_0\n",
      "model distance: 0, optimal solution reward: 0.0, improvement reward: 0.0, valid response reward: 0.0, strict format: 0.0, soft format: 0.0\n",
      "sample_1\n",
      "model distance: 471, optimal solution reward: 2.5, improvement reward: 0.0, valid response reward: 0.5, strict format: 0.0, soft format: 0.0\n",
      "sample_2\n",
      "model distance: 453, optimal solution reward: 2.5, improvement reward: 2.5, valid response reward: 0.5, strict format: 0.0, soft format: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Solving TSP Benchmark:   6%|▌         | 3/50 [06:08<1:36:59, 123.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEW PROBLEM\n",
      "target_distance: 478.50000000000006\n",
      "sample_0\n",
      "model distance: 353, optimal solution reward: 0.0, improvement reward: 0.0, valid response reward: 0.0, strict format: 0.0, soft format: 0.0\n",
      "sample_1\n",
      "model distance: 456, optimal solution reward: 2.5, improvement reward: 0.0, valid response reward: 0.5, strict format: 0.0, soft format: 0.0\n",
      "sample_2\n",
      "model distance: 0, optimal solution reward: 0.0, improvement reward: 0.0, valid response reward: 0.0, strict format: 0.0, soft format: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Solving TSP Benchmark:   8%|▊         | 4/50 [07:30<1:22:06, 107.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEW PROBLEM\n",
      "target_distance: 419.1\n",
      "sample_0\n",
      "model distance: 477, optimal solution reward: 0.0, improvement reward: 0.0, valid response reward: 0.5, strict format: 0.25, soft format: 0.25\n",
      "sample_1\n",
      "model distance: 403, optimal solution reward: 2.5, improvement reward: 0.0, valid response reward: 0.5, strict format: 0.0, soft format: 0.0\n",
      "sample_2\n",
      "model distance: 381, optimal solution reward: 2.5, improvement reward: 0.0, valid response reward: 0.5, strict format: 0.0, soft format: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Solving TSP Benchmark:  10%|█         | 5/50 [09:21<1:21:21, 108.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEW PROBLEM\n",
      "target_distance: 456.50000000000006\n",
      "sample_0\n",
      "model distance: 460, optimal solution reward: 0.0, improvement reward: 2.5, valid response reward: 0.5, strict format: 0.0, soft format: 0.0\n",
      "sample_1\n",
      "model distance: 495, optimal solution reward: 0.0, improvement reward: 0.0, valid response reward: 0.5, strict format: 0.0, soft format: 0.0\n",
      "sample_2\n",
      "model distance: 415, optimal solution reward: 2.5, improvement reward: 2.5, valid response reward: 0.5, strict format: 0.0, soft format: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Solving TSP Benchmark:  12%|█▏        | 6/50 [10:52<1:15:12, 102.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEW PROBLEM\n",
      "target_distance: 490.6\n",
      "sample_0\n",
      "model distance: 458, optimal solution reward: 2.5, improvement reward: 0.0, valid response reward: 0.5, strict format: 0.0, soft format: 0.0\n",
      "sample_1\n",
      "model distance: 458, optimal solution reward: 2.5, improvement reward: 0.0, valid response reward: 0.5, strict format: 0.0, soft format: 0.0\n",
      "sample_2\n",
      "model distance: 458, optimal solution reward: 2.5, improvement reward: 0.0, valid response reward: 0.5, strict format: 0.25, soft format: 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Solving TSP Benchmark:  14%|█▍        | 7/50 [12:02<1:05:57, 92.04s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEW PROBLEM\n",
      "target_distance: 524.7\n",
      "sample_0\n",
      "model distance: 485, optimal solution reward: 2.5, improvement reward: 0.0, valid response reward: 0.5, strict format: 0.0, soft format: 0.0\n",
      "sample_1\n",
      "model distance: 477, optimal solution reward: 2.5, improvement reward: 0.0, valid response reward: 0.5, strict format: 0.0, soft format: 0.0\n",
      "sample_2\n",
      "model distance: 648, optimal solution reward: 0.0, improvement reward: 0.0, valid response reward: 0.5, strict format: 0.0, soft format: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Solving TSP Benchmark:  16%|█▌        | 8/50 [14:08<1:11:52, 102.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEW PROBLEM\n",
      "target_distance: 435.6\n",
      "sample_0\n",
      "model distance: 561, optimal solution reward: 0.0, improvement reward: 0.0, valid response reward: 0.5, strict format: 0.25, soft format: 0.25\n",
      "sample_1\n",
      "model distance: 451, optimal solution reward: 0.0, improvement reward: 0.0, valid response reward: 0.5, strict format: 0.0, soft format: 0.0\n",
      "sample_2\n",
      "model distance: 0, optimal solution reward: 0.0, improvement reward: 0.0, valid response reward: 0.0, strict format: 0.0, soft format: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Solving TSP Benchmark:  18%|█▊        | 9/50 [15:35<1:06:55, 97.94s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEW PROBLEM\n",
      "target_distance: 498.30000000000007\n",
      "sample_0\n",
      "model distance: 487, optimal solution reward: 2.5, improvement reward: 2.5, valid response reward: 0.5, strict format: 0.0, soft format: 0.0\n",
      "sample_1\n",
      "model distance: 532, optimal solution reward: 0.0, improvement reward: 0.0, valid response reward: 0.5, strict format: 0.0, soft format: 0.0\n",
      "sample_2\n",
      "model distance: 453, optimal solution reward: 2.5, improvement reward: 2.5, valid response reward: 0.5, strict format: 0.0, soft format: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Solving TSP Benchmark:  20%|██        | 10/50 [16:30<56:20, 84.51s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEW PROBLEM\n",
      "target_distance: 573.1\n",
      "sample_0\n",
      "model distance: 522, optimal solution reward: 2.5, improvement reward: 2.5, valid response reward: 0.5, strict format: 0.0, soft format: 0.0\n",
      "sample_1\n",
      "model distance: 522, optimal solution reward: 2.5, improvement reward: 2.5, valid response reward: 0.5, strict format: 0.25, soft format: 0.25\n",
      "sample_2\n",
      "model distance: 522, optimal solution reward: 2.5, improvement reward: 2.5, valid response reward: 0.5, strict format: 0.0, soft format: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Solving TSP Benchmark:  22%|██▏       | 11/50 [18:04<56:55, 87.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEW PROBLEM\n",
      "target_distance: 523.6\n",
      "sample_0\n",
      "model distance: 549, optimal solution reward: 0.0, improvement reward: 2.5, valid response reward: 0.5, strict format: 0.0, soft format: 0.0\n",
      "sample_1\n",
      "model distance: 530, optimal solution reward: 0.0, improvement reward: 2.5, valid response reward: 0.5, strict format: 0.25, soft format: 0.25\n",
      "sample_2\n",
      "model distance: 571, optimal solution reward: 0.0, improvement reward: 2.5, valid response reward: 0.5, strict format: 0.25, soft format: 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Solving TSP Benchmark:  24%|██▍       | 12/50 [19:30<55:05, 86.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEW PROBLEM\n",
      "target_distance: 409.20000000000005\n",
      "sample_0\n",
      "model distance: 409, optimal solution reward: 2.5, improvement reward: 2.5, valid response reward: 0.5, strict format: 0.0, soft format: 0.0\n",
      "sample_1\n",
      "model distance: 478, optimal solution reward: 0.0, improvement reward: 0.0, valid response reward: 0.5, strict format: 0.0, soft format: 0.0\n",
      "sample_2\n",
      "model distance: 441, optimal solution reward: 0.0, improvement reward: 0.0, valid response reward: 0.5, strict format: 0.25, soft format: 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Solving TSP Benchmark:  26%|██▌       | 13/50 [20:43<51:08, 82.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEW PROBLEM\n",
      "target_distance: 607.2\n",
      "sample_0\n",
      "model distance: 0, optimal solution reward: 0.0, improvement reward: 0.0, valid response reward: 0.0, strict format: 0.25, soft format: 0.25\n",
      "sample_1\n",
      "model distance: 592, optimal solution reward: 2.5, improvement reward: 0.0, valid response reward: 0.5, strict format: 0.25, soft format: 0.25\n",
      "sample_2\n",
      "model distance: 603, optimal solution reward: 2.5, improvement reward: 0.0, valid response reward: 0.5, strict format: 0.25, soft format: 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Solving TSP Benchmark:  28%|██▊       | 14/50 [22:02<48:59, 81.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEW PROBLEM\n",
      "target_distance: 522.5\n",
      "sample_0\n",
      "model distance: 475, optimal solution reward: 2.5, improvement reward: 0.0, valid response reward: 0.5, strict format: 0.0, soft format: 0.0\n",
      "sample_1\n",
      "model distance: 604, optimal solution reward: 0.0, improvement reward: 0.0, valid response reward: 0.5, strict format: 0.25, soft format: 0.25\n",
      "sample_2\n",
      "model distance: 601, optimal solution reward: 0.0, improvement reward: 0.0, valid response reward: 0.5, strict format: 0.25, soft format: 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Solving TSP Benchmark:  30%|███       | 15/50 [22:36<39:12, 67.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEW PROBLEM\n",
      "target_distance: 403.70000000000005\n",
      "sample_0\n",
      "model distance: 539, optimal solution reward: 0.0, improvement reward: 0.0, valid response reward: 0.5, strict format: 0.0, soft format: 0.0\n",
      "sample_1\n",
      "model distance: 455, optimal solution reward: 0.0, improvement reward: 0.0, valid response reward: 0.5, strict format: 0.25, soft format: 0.25\n",
      "sample_2\n",
      "model distance: 416, optimal solution reward: 0.0, improvement reward: 0.0, valid response reward: 0.5, strict format: 0.0, soft format: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Solving TSP Benchmark:  32%|███▏      | 16/50 [23:46<38:30, 67.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEW PROBLEM\n",
      "target_distance: 508.20000000000005\n",
      "sample_0\n",
      "model distance: 462, optimal solution reward: 2.5, improvement reward: 2.5, valid response reward: 0.5, strict format: 0.0, soft format: 0.0\n",
      "sample_1\n",
      "model distance: 690, optimal solution reward: 0.0, improvement reward: 0.0, valid response reward: 0.5, strict format: 0.25, soft format: 0.25\n",
      "sample_2\n",
      "model distance: 462, optimal solution reward: 2.5, improvement reward: 2.5, valid response reward: 0.5, strict format: 0.0, soft format: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Solving TSP Benchmark:  34%|███▍      | 17/50 [25:12<40:22, 73.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEW PROBLEM\n",
      "target_distance: 444.40000000000003\n",
      "sample_0\n",
      "model distance: 425, optimal solution reward: 2.5, improvement reward: 0.0, valid response reward: 0.5, strict format: 0.0, soft format: 0.0\n",
      "sample_1\n",
      "model distance: 412, optimal solution reward: 2.5, improvement reward: 0.0, valid response reward: 0.5, strict format: 0.25, soft format: 0.25\n",
      "sample_2\n",
      "model distance: 413, optimal solution reward: 2.5, improvement reward: 0.0, valid response reward: 0.5, strict format: 0.0, soft format: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Solving TSP Benchmark:  36%|███▌      | 18/50 [27:04<45:26, 85.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEW PROBLEM\n",
      "target_distance: 458.70000000000005\n",
      "sample_0\n",
      "model distance: 637, optimal solution reward: 0.0, improvement reward: 0.0, valid response reward: 0.5, strict format: 0.0, soft format: 0.0\n",
      "sample_1\n",
      "model distance: 451, optimal solution reward: 2.5, improvement reward: 0.0, valid response reward: 0.5, strict format: 0.0, soft format: 0.0\n",
      "sample_2\n",
      "model distance: 442, optimal solution reward: 2.5, improvement reward: 0.0, valid response reward: 0.5, strict format: 0.0, soft format: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Solving TSP Benchmark:  38%|███▊      | 19/50 [28:12<41:15, 79.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEW PROBLEM\n",
      "target_distance: 575.3000000000001\n",
      "sample_0\n",
      "model distance: 637, optimal solution reward: 0.0, improvement reward: 0.0, valid response reward: 0.5, strict format: 0.0, soft format: 0.0\n",
      "sample_1\n",
      "model distance: 605, optimal solution reward: 0.0, improvement reward: 0.0, valid response reward: 0.5, strict format: 0.0, soft format: 0.0\n",
      "sample_2\n",
      "model distance: 523, optimal solution reward: 2.5, improvement reward: 2.5, valid response reward: 0.5, strict format: 0.0, soft format: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Solving TSP Benchmark:  40%|████      | 20/50 [30:17<46:46, 93.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEW PROBLEM\n",
      "target_distance: 382.8\n",
      "sample_0\n",
      "model distance: 388, optimal solution reward: 0.0, improvement reward: 0.0, valid response reward: 0.5, strict format: 0.25, soft format: 0.25\n",
      "sample_1\n",
      "model distance: 348, optimal solution reward: 2.5, improvement reward: 0.0, valid response reward: 0.5, strict format: 0.0, soft format: 0.0\n",
      "sample_2\n",
      "model distance: 0, optimal solution reward: 0.0, improvement reward: 0.0, valid response reward: 0.0, strict format: 0.0, soft format: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Solving TSP Benchmark:  42%|████▏     | 21/50 [32:23<49:50, 103.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEW PROBLEM\n",
      "target_distance: 554.4000000000001\n",
      "sample_0\n",
      "model distance: 0, optimal solution reward: 0.0, improvement reward: 0.0, valid response reward: 0.0, strict format: 0.0, soft format: 0.0\n",
      "sample_1\n",
      "model distance: 504, optimal solution reward: 2.5, improvement reward: 2.5, valid response reward: 0.5, strict format: 0.25, soft format: 0.25\n",
      "sample_2\n",
      "model distance: 609, optimal solution reward: 0.0, improvement reward: 0.0, valid response reward: 0.5, strict format: 0.0, soft format: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Solving TSP Benchmark:  44%|████▍     | 22/50 [34:28<51:15, 109.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEW PROBLEM\n",
      "target_distance: 436.70000000000005\n",
      "sample_0\n",
      "model distance: 630, optimal solution reward: 0.0, improvement reward: 2.5, valid response reward: 0.5, strict format: 0.0, soft format: 0.0\n",
      "sample_1\n",
      "model distance: 0, optimal solution reward: 0.0, improvement reward: 0.0, valid response reward: 0.0, strict format: 0.0, soft format: 0.0\n",
      "sample_2\n",
      "model distance: 467, optimal solution reward: 0.0, improvement reward: 2.5, valid response reward: 0.5, strict format: 0.0, soft format: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Solving TSP Benchmark:  46%|████▌     | 23/50 [35:59<46:54, 104.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEW PROBLEM\n",
      "target_distance: 592.9000000000001\n",
      "sample_0\n",
      "model distance: 600, optimal solution reward: 0.0, improvement reward: 2.5, valid response reward: 0.5, strict format: 0.0, soft format: 0.0\n",
      "sample_1\n",
      "model distance: 702, optimal solution reward: 0.0, improvement reward: 0.0, valid response reward: 0.5, strict format: 0.0, soft format: 0.0\n",
      "sample_2\n",
      "model distance: 550, optimal solution reward: 2.5, improvement reward: 2.5, valid response reward: 0.5, strict format: 0.0, soft format: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Solving TSP Benchmark:  48%|████▊     | 24/50 [38:05<47:56, 110.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEW PROBLEM\n",
      "target_distance: 531.3000000000001\n",
      "sample_0\n",
      "model distance: 0, optimal solution reward: 0.0, improvement reward: 0.0, valid response reward: 0.0, strict format: 0.0, soft format: 0.0\n",
      "sample_1\n",
      "model distance: 646, optimal solution reward: 0.0, improvement reward: 0.0, valid response reward: 0.5, strict format: 0.0, soft format: 0.0\n",
      "sample_2\n",
      "model distance: 658, optimal solution reward: 0.0, improvement reward: 0.0, valid response reward: 0.5, strict format: 0.25, soft format: 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Solving TSP Benchmark:  50%|█████     | 25/50 [40:10<47:57, 115.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEW PROBLEM\n",
      "target_distance: 556.6\n",
      "sample_0\n",
      "model distance: 533, optimal solution reward: 2.5, improvement reward: 2.5, valid response reward: 0.5, strict format: 0.25, soft format: 0.25\n",
      "sample_1\n",
      "model distance: 506, optimal solution reward: 2.5, improvement reward: 2.5, valid response reward: 0.5, strict format: 0.0, soft format: 0.0\n",
      "sample_2\n",
      "model distance: 0, optimal solution reward: 0.0, improvement reward: 0.0, valid response reward: 0.0, strict format: 0.0, soft format: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Solving TSP Benchmark:  52%|█████▏    | 26/50 [41:59<45:19, 113.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEW PROBLEM\n",
      "target_distance: 313.5\n",
      "sample_0\n",
      "model distance: 315, optimal solution reward: 0.0, improvement reward: 0.0, valid response reward: 0.5, strict format: 0.0, soft format: 0.0\n",
      "sample_1\n",
      "model distance: 286, optimal solution reward: 2.5, improvement reward: 0.0, valid response reward: 0.5, strict format: 0.25, soft format: 0.25\n",
      "sample_2\n",
      "model distance: 258, optimal solution reward: 0.0, improvement reward: 0.0, valid response reward: 0.0, strict format: 0.25, soft format: 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Solving TSP Benchmark:  54%|█████▍    | 27/50 [42:47<35:51, 93.56s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEW PROBLEM\n",
      "target_distance: 444.40000000000003\n",
      "sample_0\n",
      "model distance: 460, optimal solution reward: 0.0, improvement reward: 0.0, valid response reward: 0.0, strict format: 0.25, soft format: 0.25\n",
      "sample_1\n",
      "model distance: 404, optimal solution reward: 2.5, improvement reward: 2.5, valid response reward: 0.5, strict format: 0.25, soft format: 0.25\n",
      "sample_2\n",
      "model distance: 498, optimal solution reward: 0.0, improvement reward: 0.0, valid response reward: 0.5, strict format: 0.0, soft format: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Solving TSP Benchmark:  56%|█████▌    | 28/50 [44:52<37:48, 103.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEW PROBLEM\n",
      "target_distance: 618.2\n",
      "sample_0\n",
      "model distance: 0, optimal solution reward: 0.0, improvement reward: 0.0, valid response reward: 0.0, strict format: 0.0, soft format: 0.0\n",
      "sample_1\n",
      "model distance: 562, optimal solution reward: 2.5, improvement reward: 0.0, valid response reward: 0.5, strict format: 0.25, soft format: 0.25\n",
      "sample_2\n",
      "model distance: 651, optimal solution reward: 0.0, improvement reward: 0.0, valid response reward: 0.5, strict format: 0.0, soft format: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Solving TSP Benchmark:  58%|█████▊    | 29/50 [46:41<36:39, 104.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEW PROBLEM\n",
      "target_distance: 479.6\n",
      "sample_0\n",
      "model distance: 527, optimal solution reward: 0.0, improvement reward: 0.0, valid response reward: 0.5, strict format: 0.0, soft format: 0.0\n",
      "sample_1\n",
      "model distance: 453, optimal solution reward: 2.5, improvement reward: 2.5, valid response reward: 0.5, strict format: 0.0, soft format: 0.0\n",
      "sample_2\n",
      "model distance: 544, optimal solution reward: 0.0, improvement reward: 0.0, valid response reward: 0.5, strict format: 0.0, soft format: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Solving TSP Benchmark:  60%|██████    | 30/50 [48:14<33:46, 101.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEW PROBLEM\n",
      "target_distance: 349.8\n",
      "sample_0\n",
      "model distance: 352, optimal solution reward: 0.0, improvement reward: 2.5, valid response reward: 0.5, strict format: 0.0, soft format: 0.0\n",
      "sample_1\n",
      "model distance: 372, optimal solution reward: 0.0, improvement reward: 0.0, valid response reward: 0.5, strict format: 0.0, soft format: 0.0\n",
      "sample_2\n",
      "model distance: 361, optimal solution reward: 0.0, improvement reward: 0.0, valid response reward: 0.5, strict format: 0.0, soft format: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Solving TSP Benchmark:  62%|██████▏   | 31/50 [49:17<28:23, 89.66s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEW PROBLEM\n",
      "target_distance: 493.90000000000003\n",
      "sample_0\n",
      "model distance: 473, optimal solution reward: 2.5, improvement reward: 2.5, valid response reward: 0.5, strict format: 0.0, soft format: 0.0\n",
      "sample_1\n",
      "model distance: 484, optimal solution reward: 2.5, improvement reward: 2.5, valid response reward: 0.5, strict format: 0.0, soft format: 0.0\n",
      "sample_2\n",
      "model distance: 484, optimal solution reward: 2.5, improvement reward: 2.5, valid response reward: 0.5, strict format: 0.0, soft format: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Solving TSP Benchmark:  64%|██████▍   | 32/50 [51:18<29:45, 99.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEW PROBLEM\n",
      "target_distance: 675.4000000000001\n",
      "sample_0\n",
      "model distance: 884, optimal solution reward: 0.0, improvement reward: 0.0, valid response reward: 0.5, strict format: 0.0, soft format: 0.0\n",
      "sample_1\n",
      "model distance: 624, optimal solution reward: 2.5, improvement reward: 2.5, valid response reward: 0.5, strict format: 0.25, soft format: 0.25\n",
      "sample_2\n",
      "model distance: 675, optimal solution reward: 2.5, improvement reward: 0.0, valid response reward: 0.5, strict format: 0.0, soft format: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Solving TSP Benchmark:  66%|██████▌   | 33/50 [53:08<29:01, 102.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEW PROBLEM\n",
      "target_distance: 466.40000000000003\n",
      "sample_0\n",
      "model distance: 520, optimal solution reward: 0.0, improvement reward: 2.5, valid response reward: 0.5, strict format: 0.0, soft format: 0.0\n",
      "sample_1\n",
      "model distance: 561, optimal solution reward: 0.0, improvement reward: 0.0, valid response reward: 0.5, strict format: 0.25, soft format: 0.25\n",
      "sample_2\n",
      "model distance: 0, optimal solution reward: 0.0, improvement reward: 0.0, valid response reward: 0.0, strict format: 0.0, soft format: 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Solving TSP Benchmark:  68%|██████▊   | 34/50 [55:14<29:09, 109.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEW PROBLEM\n",
      "target_distance: 273.90000000000003\n",
      "sample_0\n",
      "model distance: 335, optimal solution reward: 0.0, improvement reward: 0.0, valid response reward: 0.5, strict format: 0.0, soft format: 0.0\n",
      "sample_1\n",
      "model distance: 0, optimal solution reward: 0.0, improvement reward: 0.0, valid response reward: 0.0, strict format: 0.0, soft format: 0.0\n",
      "sample_2\n",
      "model distance: 279, optimal solution reward: 0.0, improvement reward: 2.5, valid response reward: 0.5, strict format: 0.0, soft format: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Solving TSP Benchmark:  70%|███████   | 35/50 [57:07<27:37, 110.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEW PROBLEM\n",
      "target_distance: 534.6\n",
      "sample_0\n",
      "model distance: 534, optimal solution reward: 2.5, improvement reward: 2.5, valid response reward: 0.5, strict format: 0.0, soft format: 0.0\n",
      "sample_1\n",
      "model distance: 587, optimal solution reward: 0.0, improvement reward: 2.5, valid response reward: 0.5, strict format: 0.25, soft format: 0.25\n",
      "sample_2\n",
      "model distance: 563, optimal solution reward: 0.0, improvement reward: 2.5, valid response reward: 0.5, strict format: 0.0, soft format: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Solving TSP Benchmark:  72%|███████▏  | 36/50 [58:24<23:26, 100.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEW PROBLEM\n",
      "target_distance: 622.6\n",
      "sample_0\n",
      "model distance: 622, optimal solution reward: 2.5, improvement reward: 0.0, valid response reward: 0.5, strict format: 0.25, soft format: 0.25\n",
      "sample_1\n",
      "model distance: 566, optimal solution reward: 2.5, improvement reward: 2.5, valid response reward: 0.5, strict format: 0.25, soft format: 0.25\n",
      "sample_2\n",
      "model distance: 622, optimal solution reward: 2.5, improvement reward: 0.0, valid response reward: 0.5, strict format: 0.25, soft format: 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Solving TSP Benchmark:  74%|███████▍  | 37/50 [59:21<18:58, 87.58s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEW PROBLEM\n",
      "target_distance: 522.5\n",
      "sample_0\n",
      "model distance: 497, optimal solution reward: 2.5, improvement reward: 2.5, valid response reward: 0.5, strict format: 0.0, soft format: 0.0\n",
      "sample_1\n",
      "model distance: 475, optimal solution reward: 2.5, improvement reward: 2.5, valid response reward: 0.5, strict format: 0.0, soft format: 0.0\n",
      "sample_2\n",
      "model distance: 994, optimal solution reward: 0.0, improvement reward: 0.0, valid response reward: 0.0, strict format: 0.25, soft format: 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Solving TSP Benchmark:  76%|███████▌  | 38/50 [1:01:03<18:20, 91.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEW PROBLEM\n",
      "target_distance: 405.90000000000003\n",
      "sample_0\n",
      "model distance: 369, optimal solution reward: 2.5, improvement reward: 2.5, valid response reward: 0.5, strict format: 0.0, soft format: 0.0\n",
      "sample_1\n",
      "model distance: 369, optimal solution reward: 2.5, improvement reward: 2.5, valid response reward: 0.5, strict format: 0.0, soft format: 0.0\n",
      "sample_2\n",
      "model distance: 541, optimal solution reward: 0.0, improvement reward: 0.0, valid response reward: 0.5, strict format: 0.25, soft format: 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Solving TSP Benchmark:  78%|███████▊  | 39/50 [1:02:27<16:23, 89.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEW PROBLEM\n",
      "target_distance: 547.8000000000001\n",
      "sample_0\n",
      "model distance: 504, optimal solution reward: 2.5, improvement reward: 0.0, valid response reward: 0.5, strict format: 0.0, soft format: 0.25\n",
      "sample_1\n",
      "model distance: 506, optimal solution reward: 2.5, improvement reward: 0.0, valid response reward: 0.5, strict format: 0.0, soft format: 0.0\n",
      "sample_2\n",
      "model distance: 504, optimal solution reward: 2.5, improvement reward: 0.0, valid response reward: 0.5, strict format: 0.0, soft format: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Solving TSP Benchmark:  80%|████████  | 40/50 [1:04:15<15:52, 95.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEW PROBLEM\n",
      "target_distance: 704.0\n",
      "sample_0\n",
      "model distance: 640, optimal solution reward: 2.5, improvement reward: 0.0, valid response reward: 0.5, strict format: 0.0, soft format: 0.0\n",
      "sample_1\n",
      "model distance: 640, optimal solution reward: 2.5, improvement reward: 0.0, valid response reward: 0.5, strict format: 0.0, soft format: 0.0\n",
      "sample_2\n",
      "model distance: 0, optimal solution reward: 0.0, improvement reward: 0.0, valid response reward: 0.0, strict format: 0.0, soft format: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Solving TSP Benchmark:  82%|████████▏ | 41/50 [1:06:03<14:49, 98.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEW PROBLEM\n",
      "target_distance: 534.6\n",
      "sample_0\n",
      "model distance: 486, optimal solution reward: 2.5, improvement reward: 0.0, valid response reward: 0.5, strict format: 0.0, soft format: 0.0\n",
      "sample_1\n",
      "model distance: 504, optimal solution reward: 2.5, improvement reward: 0.0, valid response reward: 0.5, strict format: 0.25, soft format: 0.25\n",
      "sample_2\n",
      "model distance: 649, optimal solution reward: 0.0, improvement reward: 0.0, valid response reward: 0.5, strict format: 0.0, soft format: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Solving TSP Benchmark:  84%|████████▍ | 42/50 [1:08:08<14:14, 106.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEW PROBLEM\n",
      "target_distance: 608.3000000000001\n",
      "sample_0\n",
      "model distance: 0, optimal solution reward: 0.0, improvement reward: 0.0, valid response reward: 0.0, strict format: 0.0, soft format: 0.0\n",
      "sample_1\n",
      "model distance: 598, optimal solution reward: 2.5, improvement reward: 0.0, valid response reward: 0.5, strict format: 0.0, soft format: 0.0\n",
      "sample_2\n",
      "model distance: 553, optimal solution reward: 2.5, improvement reward: 2.5, valid response reward: 0.5, strict format: 0.0, soft format: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Solving TSP Benchmark:  86%|████████▌ | 43/50 [1:09:43<12:02, 103.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEW PROBLEM\n",
      "target_distance: 449.90000000000003\n",
      "sample_0\n",
      "model distance: 409, optimal solution reward: 2.5, improvement reward: 2.5, valid response reward: 0.5, strict format: 0.0, soft format: 0.0\n",
      "sample_1\n",
      "model distance: 639, optimal solution reward: 0.0, improvement reward: 0.0, valid response reward: 0.5, strict format: 0.25, soft format: 0.25\n",
      "sample_2\n",
      "model distance: 417, optimal solution reward: 2.5, improvement reward: 2.5, valid response reward: 0.5, strict format: 0.0, soft format: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Solving TSP Benchmark:  88%|████████▊ | 44/50 [1:11:29<10:24, 104.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEW PROBLEM\n",
      "target_distance: 313.5\n",
      "sample_0\n",
      "model distance: 285, optimal solution reward: 2.5, improvement reward: 2.5, valid response reward: 0.5, strict format: 0.0, soft format: 0.0\n",
      "sample_1\n",
      "model distance: 285, optimal solution reward: 2.5, improvement reward: 2.5, valid response reward: 0.5, strict format: 0.0, soft format: 0.0\n",
      "sample_2\n",
      "model distance: 292, optimal solution reward: 2.5, improvement reward: 0.0, valid response reward: 0.5, strict format: 0.0, soft format: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Solving TSP Benchmark:  90%|█████████ | 45/50 [1:12:55<08:12, 98.52s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEW PROBLEM\n",
      "target_distance: 368.50000000000006\n",
      "sample_0\n",
      "model distance: 357, optimal solution reward: 2.5, improvement reward: 2.5, valid response reward: 0.5, strict format: 0.0, soft format: 0.0\n",
      "sample_1\n",
      "model distance: 335, optimal solution reward: 2.5, improvement reward: 2.5, valid response reward: 0.5, strict format: 0.25, soft format: 0.25\n",
      "sample_2\n",
      "model distance: 454, optimal solution reward: 0.0, improvement reward: 0.0, valid response reward: 0.5, strict format: 0.25, soft format: 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Solving TSP Benchmark:  92%|█████████▏| 46/50 [1:15:00<07:06, 106.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEW PROBLEM\n",
      "target_distance: 442.20000000000005\n",
      "sample_0\n",
      "model distance: 0, optimal solution reward: 0.0, improvement reward: 0.0, valid response reward: 0.0, strict format: 0.0, soft format: 0.0\n",
      "sample_1\n",
      "model distance: 429, optimal solution reward: 2.5, improvement reward: 0.0, valid response reward: 0.5, strict format: 0.0, soft format: 0.0\n",
      "sample_2\n",
      "model distance: 0, optimal solution reward: 0.0, improvement reward: 0.0, valid response reward: 0.0, strict format: 0.0, soft format: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Solving TSP Benchmark:  94%|█████████▍| 47/50 [1:15:48<04:27, 89.11s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEW PROBLEM\n",
      "target_distance: 465.3\n",
      "sample_0\n",
      "model distance: 423, optimal solution reward: 2.5, improvement reward: 2.5, valid response reward: 0.5, strict format: 0.0, soft format: 0.0\n",
      "sample_1\n",
      "model distance: 456, optimal solution reward: 2.5, improvement reward: 2.5, valid response reward: 0.5, strict format: 0.0, soft format: 0.0\n",
      "sample_2\n",
      "model distance: 456, optimal solution reward: 2.5, improvement reward: 2.5, valid response reward: 0.5, strict format: 0.0, soft format: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Solving TSP Benchmark:  96%|█████████▌| 48/50 [1:17:39<03:11, 95.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEW PROBLEM\n",
      "target_distance: 526.9000000000001\n",
      "sample_0\n",
      "model distance: 510, optimal solution reward: 2.5, improvement reward: 2.5, valid response reward: 0.5, strict format: 0.0, soft format: 0.0\n",
      "sample_1\n",
      "model distance: 510, optimal solution reward: 2.5, improvement reward: 2.5, valid response reward: 0.5, strict format: 0.0, soft format: 0.0\n",
      "sample_2\n",
      "model distance: 708, optimal solution reward: 0.0, improvement reward: 0.0, valid response reward: 0.5, strict format: 0.0, soft format: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Solving TSP Benchmark:  98%|█████████▊| 49/50 [1:18:28<01:21, 81.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEW PROBLEM\n",
      "target_distance: 342.1\n",
      "sample_0\n",
      "model distance: 311, optimal solution reward: 2.5, improvement reward: 2.5, valid response reward: 0.5, strict format: 0.0, soft format: 0.0\n",
      "sample_1\n",
      "model distance: 314, optimal solution reward: 2.5, improvement reward: 0.0, valid response reward: 0.5, strict format: 0.25, soft format: 0.25\n",
      "sample_2\n",
      "model distance: 349, optimal solution reward: 0.0, improvement reward: 0.0, valid response reward: 0.5, strict format: 0.25, soft format: 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Solving TSP Benchmark: 100%|██████████| 50/50 [1:20:00<00:00, 96.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEW PROBLEM\n",
      "target_distance: 522.5\n",
      "sample_0\n",
      "model distance: 0, optimal solution reward: 0.0, improvement reward: 0.0, valid response reward: 0.0, strict format: 0.0, soft format: 0.0\n",
      "sample_1\n",
      "model distance: 521, optimal solution reward: 2.5, improvement reward: 0.0, valid response reward: 0.5, strict format: 0.0, soft format: 0.0\n",
      "sample_2\n",
      "model distance: 542, optimal solution reward: 0.0, improvement reward: 0.0, valid response reward: 0.0, strict format: 0.0, soft format: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Load benchmark dataset\n",
    "dataset = load_tsp_problem_dataset(BENCHMARK_DATASET)\n",
    "\n",
    "pbar = tqdm(total=len(dataset) * len(dataset[\"size_5\"]), desc=\"Solving TSP Benchmark\")\n",
    "\n",
    "results = {}\n",
    "\n",
    "# Solve benchmark dataset\n",
    "for size_key in dataset:\n",
    "  problems = dataset[size_key]\n",
    "\n",
    "  size_results = []\n",
    "\n",
    "  for problem in problems:\n",
    "    prompt = problem['prompt']\n",
    "    solution = problem['solution']\n",
    "\n",
    "    # Generate 3 completions per prompt\n",
    "    generate_out = generate(prompt, num_samples=3)\n",
    "\n",
    "    # Calculate average rewards across 3 samples\n",
    "    reward_out = apply_reward_functions(problem, generate_out['responses'])\n",
    "\n",
    "    # Remove completions from gen out\n",
    "    del generate_out['responses']\n",
    "\n",
    "    # Append problem summary to results\n",
    "    generate_out.update(reward_out)\n",
    "    problem_summary = generate_out\n",
    "    size_results.append(problem_summary)\n",
    "\n",
    "    # Update progress bar\n",
    "    pbar.update(1)\n",
    "  \n",
    "  results[size_key] = size_results\n",
    "\n",
    "pbar.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Results and Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "summary = {}\n",
    "del results['summary']\n",
    "\n",
    "for size_key in results:\n",
    "  size_results = results[size_key]\n",
    "  size_summary = {}\n",
    "  n = len(size_results)\n",
    "\n",
    "  # Calculate summary per size\n",
    "  average_input_token_count = sum([problem['input token count'] for problem in size_results]) / n\n",
    "  average_output_token_count = sum([problem['average output token count'] for problem in size_results]) / n\n",
    "  average_optimal_solution_reward = sum([problem['average optimal solution reward'] for problem in size_results]) / n\n",
    "  average_improved_reward = sum([problem['average improvement reward'] for problem in size_results]) / n\n",
    "  average_valid_response_reward = sum([problem['average valid response reward'] for problem in size_results]) / n\n",
    "  average_strict_format_reward = sum([problem['average strict format reward'] for problem in size_results]) / n\n",
    "  average_soft_format_reward = sum([problem['average soft format reward'] for problem in size_results]) / n\n",
    "\n",
    "  # Load size summary\n",
    "  size_summary['average input token count'] = average_input_token_count\n",
    "  size_summary['average output token count'] = average_output_token_count\n",
    "  size_summary['average optimal solution reward'] = average_optimal_solution_reward\n",
    "  size_summary['average improvement reward'] = average_improved_reward\n",
    "  size_summary['average valid response reward'] = average_valid_response_reward\n",
    "  size_summary['average strict format reward'] = average_strict_format_reward\n",
    "  size_summary['average soft format reward'] = average_soft_format_reward\n",
    "\n",
    "  # Append size summary to summary\n",
    "  summary[size_key] = size_summary\n",
    "\n",
    "# Append summary to results\n",
    "results['summary'] = summary\n",
    "\n",
    "# Save benchmark results\n",
    "with open(\"benchmark_results2.json\", \"w\") as file:\n",
    "  json.dump(results, file, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (unsloth_env)",
   "language": "python",
   "name": "unsloth_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
